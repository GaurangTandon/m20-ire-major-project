{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import math\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from scipy.sparse import lil_matrix\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "ps = PorterStemmer()\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import warnings \n",
    "  \n",
    "warnings.filterwarnings(action = 'ignore') \n",
    "  \n",
    "import gensim \n",
    "from gensim.models import Word2Vec \n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Dataset.csv\")\n",
    "df=df.drop(['Unnamed: 2'], axis = 1)\n",
    "coaData = pd.read_csv(\"coa.csv\")\n",
    "nlpData = pd.read_csv(\"1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractedsentences= df['Sentence']\n",
    "labelSentence = df['Validity']\n",
    "coaSentences = coaData[\"Sentence\"]\n",
    "nlpSentences = nlpData[\"Sentence\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "X_train_tfidf = vectorizer.fit_transform(extractedsentences)\n",
    "coa_test_tfidf = vectorizer.transform(coaSentences)\n",
    "nlp_test_tfidf = vectorizer.transform(nlpSentences)\n",
    "\n",
    "y = np.array(labelSentence)\n",
    "y= y.astype('int')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "k = np.arange(2,8)\n",
    "for depth in k:\n",
    "    # train data\n",
    "    clf = DecisionTreeClassifier(max_depth=depth, random_state=1)\n",
    "    clf.fit(X_train_tfidf,y)\n",
    "\n",
    "    # test data\n",
    "#     print(\"NLP Sentences\")\n",
    "    prediction= clf.predict(nlp_test_tfidf)\n",
    "#     for j in range (len(prediction)):\n",
    "#         if(prediction[j]==1):\n",
    "#             print(nlpSentences[j])\n",
    "#     print()\n",
    "#     print(\"COA Sentences\")\n",
    "    prediction= clf.predict(coa_test_tfidf)\n",
    "#     for j in range (len(prediction)):\n",
    "#         if(prediction[j]==1):\n",
    "#             print(coaSentences[j])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial SVM (Expermient with C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "k = np.arange(2,8)\n",
    "for c in k:\n",
    "    classifier= svm.SVC(kernel= 'poly',degree=2, C= c, decision_function_shape='ovr')\n",
    "    classifier.fit(X_train_tfidf,y)\n",
    "    \n",
    "#     print(\"NLP Sentences\")\n",
    "    prediction= classifier.predict(nlp_test_tfidf)\n",
    "#     for j in range (len(prediction)):\n",
    "#         if(prediction[j]==1):\n",
    "#             print(nlpSentences[j])\n",
    "#     print()\n",
    "#     print(\"COA Sentences\")\n",
    "    prediction= classifier.predict(coa_test_tfidf)\n",
    "#     for j in range (len(prediction)):\n",
    "#         if(prediction[j]==1):\n",
    "#             print(coaSentences[j])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial SVM (Experiment with Degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "k = np.arange(2,4)\n",
    "for degree in k:\n",
    "    classifier= svm.SVC(kernel= 'poly',degree=degree, C= 2, decision_function_shape='ovr')\n",
    "    classifier.fit(X_train_tfidf,y)\n",
    "#     print(\"NLP Sentences\")\n",
    "    prediction= classifier.predict(nlp_test_tfidf)\n",
    "#     for j in range (len(prediction)):\n",
    "#         if(prediction[j]==1):\n",
    "#             print(nlpSentences[j])\n",
    "#     print()\n",
    "#     print(\"COA Sentences\")\n",
    "    prediction= classifier.predict(coa_test_tfidf)\n",
    "#     for j in range (len(prediction)):\n",
    "#         if(prediction[j]==1):\n",
    "#             print(coaSentences[j])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "k = np.arange(2,10)\n",
    "for c in k:\n",
    "    classifier= svm.SVC(kernel= 'linear', C= c, decision_function_shape='ovr')\n",
    "    classifier.fit(X_train_tfidf,y)\n",
    "#     print(\"NLP Sentences\")\n",
    "    prediction= classifier.predict(nlp_test_tfidf)\n",
    "#     for j in range (len(prediction)):\n",
    "#         if(prediction[j]==1):\n",
    "#             print(nlpSentences[j])\n",
    "#     print()\n",
    "#     print(\"COA Sentences\")\n",
    "    prediction= classifier.predict(coa_test_tfidf)\n",
    "#     for j in range (len(prediction)):\n",
    "#         if(prediction[j]==1):\n",
    "#             print(coaSentences[j])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "k = np.arange(3,10)\n",
    "for numberOfNeighbours in k:\n",
    "    knn = KNeighborsClassifier(n_neighbors=numberOfNeighbours, metric='euclidean')\n",
    "    knn.fit(X_train_tfidf, y)\n",
    "#     print(\"NLP Sentences\")\n",
    "    prediction= knn.predict(nlp_test_tfidf)\n",
    "#     for j in range (len(prediction)):\n",
    "#         if(prediction[j]==1):\n",
    "#             print(nlpSentences[j])\n",
    "#     print()\n",
    "#     print(\"COA Sentences\")\n",
    "    prediction= knn.predict(coa_test_tfidf)\n",
    "#     for j in range (len(prediction)):\n",
    "#         if(prediction[j]==1):\n",
    "#             print(coaSentences[j])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "k = np.arange(2,10)\n",
    "for depth in k:\n",
    "    clf = RandomForestClassifier(max_depth=depth, random_state=1)\n",
    "    clf.fit(X_train_tfidf, y)\n",
    "#     print(\"NLP Sentences\")\n",
    "    prediction= clf.predict(nlp_test_tfidf)\n",
    "#     for j in range (len(prediction)):\n",
    "#         if(prediction[j]==1):\n",
    "#             print(nlpSentences[j])\n",
    "#     print()\n",
    "#     print(\"COA Sentences\")\n",
    "    prediction= clf.predict(coa_test_tfidf)\n",
    "#     for j in range (len(prediction)):\n",
    "#         if(prediction[j]==1):\n",
    "#             print(coaSentences[j])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word-2-Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "ps= PorterStemmer()\n",
    "tokenized_text= [sentence.split() for sentence in extractedsentences]\n",
    "data= []\n",
    "for tokenList in tokenized_text:\n",
    "    temp =[]\n",
    "    for token in tokenList:\n",
    "        if token not in stop_words:\n",
    "            temp.append(ps.stem(token))\n",
    "    data.append(temp)\n",
    "\n",
    "path = get_tmpfile(\"word2vec.model\")\n",
    "model = Word2Vec(data, size=100, window=5, min_count=2, workers=4)\n",
    "model.save(\"word2vec.model\")\n",
    "\n",
    "model = Word2Vec.load(\"word2vec.model\")\n",
    "\n",
    "tokenized_text= [sentence.split() for sentence in extractedsentences]\n",
    "data= []\n",
    "for tokenList in tokenized_text:\n",
    "    zerosList= [int(0) for i in range(100)]\n",
    "    temp =[]\n",
    "    temp.append(zerosList)\n",
    "    for token in tokenList:\n",
    "        if token not in stop_words and token in model:\n",
    "            temp.append(model[ps.stem(token)])\n",
    "    temp= np.array(temp)\n",
    "    temp= np.mean(temp, axis=0)\n",
    "    data.append(temp)\n",
    "\n",
    "xtrain = np.zeros((len(data),100))\n",
    "i=-1\n",
    "j=-1\n",
    "for values in data:\n",
    "    i+=1\n",
    "    j=-1\n",
    "    for q in range(values.shape[0]):\n",
    "        xtrain[i][j]=values[q]\n",
    "X_train=xtrain \n",
    "\n",
    "tokenized_text= [sentence.split() for sentence in coaSentences]\n",
    "data= []\n",
    "for tokenList in tokenized_text:\n",
    "    zerosList= [int(0) for i in range(100)]\n",
    "    temp =[]\n",
    "    temp.append(zerosList)\n",
    "    for token in tokenList:\n",
    "        if token not in stop_words and token in model:\n",
    "            temp.append(model[ps.stem(token)])\n",
    "    temp= np.array(temp)\n",
    "    temp= np.mean(temp, axis=0)\n",
    "    data.append(temp)\n",
    "\n",
    "xtrain = np.zeros((len(data),100))\n",
    "i=-1\n",
    "j=-1\n",
    "for values in data:\n",
    "    i+=1\n",
    "    j=-1\n",
    "    for q in range(values.shape[0]):\n",
    "        xtrain[i][j]=values[q]\n",
    "coa_test=xtrain \n",
    "\n",
    "tokenized_text= [sentence.split() for sentence in nlpSentences]\n",
    "data= []\n",
    "for tokenList in tokenized_text:\n",
    "    zerosList= [int(0) for i in range(100)]\n",
    "    temp =[]\n",
    "    temp.append(zerosList)\n",
    "    for token in tokenList:\n",
    "        if token not in stop_words and token in model:\n",
    "            temp.append(model[ps.stem(token)])\n",
    "    temp= np.array(temp)\n",
    "    temp= np.mean(temp, axis=0)\n",
    "    data.append(temp)\n",
    "\n",
    "xtrain = np.zeros((len(data),100))\n",
    "i=-1\n",
    "j=-1\n",
    "for values in data:\n",
    "    i+=1\n",
    "    j=-1\n",
    "    for q in range(values.shape[0]):\n",
    "        xtrain[i][j]=values[q]\n",
    "nlp_test=xtrain \n",
    "\n",
    "y = np.array(labelSentence)\n",
    "y= y.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "k = np.arange(2,8)\n",
    "for depth in k:\n",
    "    # train data\n",
    "    clf = DecisionTreeClassifier(max_depth=depth, random_state=1)\n",
    "    clf.fit(X_train,y)\n",
    "\n",
    "    # test data\n",
    "#     print(\"NLP Sentences\")\n",
    "    prediction= clf.predict(nlp_test)\n",
    "#     for j in range (len(prediction)):\n",
    "#         if(prediction[j]==1):\n",
    "#             print(nlpSentences[j])\n",
    "#     print()\n",
    "#     print(\"COA Sentences\")\n",
    "    prediction= clf.predict(coa_test)\n",
    "#     for j in range (len(prediction)):\n",
    "#         if(prediction[j]==1):\n",
    "#             print(coaSentences[j])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial SVM (Expermient with C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "k = np.arange(2,8)\n",
    "for c in k:\n",
    "    classifier= svm.SVC(kernel= 'poly',degree=2, C= c, decision_function_shape='ovr')\n",
    "    classifier.fit(X_train,y)\n",
    "    \n",
    "#     print(\"NLP Sentences\")\n",
    "    prediction= classifier.predict(nlp_test)\n",
    "#     for j in range (len(prediction)):\n",
    "#         if(prediction[j]==1):\n",
    "#             print(nlpSentences[j])\n",
    "#     print()\n",
    "#     print(\"COA Sentences\")\n",
    "#     prediction= classifier.predict(coa_test)\n",
    "#     for j in range (len(prediction)):\n",
    "#         if(prediction[j]==1):\n",
    "#             print(coaSentences[j])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial SVM (Experiment with Degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "k = np.arange(2,4)\n",
    "for degree in k:\n",
    "    classifier= svm.SVC(kernel= 'poly',degree=degree, C= 2, decision_function_shape='ovr')\n",
    "    classifier.fit(X_train,y)\n",
    "#     print(\"NLP Sentences\")\n",
    "    prediction= classifier.predict(nlp_test)\n",
    "#     for j in range (len(prediction)):\n",
    "#         if(prediction[j]==1):\n",
    "#             print(nlpSentences[j])\n",
    "#     print()\n",
    "#     print(\"COA Sentences\")\n",
    "#     prediction= classifier.predict(coa_test)\n",
    "#     for j in range (len(prediction)):\n",
    "#         if(prediction[j]==1):\n",
    "#             print(coaSentences[j])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "k = np.arange(2,10)\n",
    "for c in k:\n",
    "    classifier= svm.SVC(kernel= 'linear', C= c, decision_function_shape='ovr')\n",
    "    classifier.fit(X_train,y)\n",
    "#     print(\"NLP Sentences\")\n",
    "    prediction= classifier.predict(nlp_test)\n",
    "#     for j in range (len(prediction)):\n",
    "#         if(prediction[j]==1):\n",
    "#             print(nlpSentences[j])\n",
    "#     print()\n",
    "#     print(\"COA Sentences\")\n",
    "#     prediction= classifier.predict(coa_test)\n",
    "#     for j in range (len(prediction)):\n",
    "#         if(prediction[j]==1):\n",
    "#             print(coaSentences[j])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "k = np.arange(3,10)\n",
    "for numberOfNeighbours in k:\n",
    "    knn = KNeighborsClassifier(n_neighbors=numberOfNeighbours, metric='euclidean')\n",
    "    knn.fit(X_train, y)\n",
    "#     print(\"NLP Sentences\")\n",
    "#     prediction= knn.predict(nlp_test)\n",
    "#     for j in range (len(prediction)):\n",
    "#         if(prediction[j]==1):\n",
    "#             print(nlpSentences[j])\n",
    "#     print()\n",
    "#     print(\"COA Sentences\")\n",
    "#     prediction= knn.predict(coa_test)\n",
    "#     for j in range (len(prediction)):\n",
    "#         if(prediction[j]==1):\n",
    "#             print(coaSentences[j])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "k = np.arange(2,10)\n",
    "for depth in k:\n",
    "    clf = RandomForestClassifier(max_depth=depth, random_state=1)\n",
    "    clf.fit(X_train, y)\n",
    "#     print(\"NLP Sentences\")\n",
    "#     prediction= clf.predict(nlp_test)\n",
    "#     for j in range (len(prediction)):\n",
    "#         if(prediction[j]==1):\n",
    "#             print(nlpSentences[j])\n",
    "#     print()\n",
    "#     print(\"COA Sentences\")\n",
    "#     prediction= clf.predict(coa_test)\n",
    "#     for j in range (len(prediction)):\n",
    "#         if(prediction[j]==1):\n",
    "#             print(coaSentences[j])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
